{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "%matplotlib notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(font_scale=1.2)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean of the integrated profile</th>\n",
       "      <th>Standard deviation of the integrated profile</th>\n",
       "      <th>Excess kurtosis of the integrated profile</th>\n",
       "      <th>Skewness of the integrated profile</th>\n",
       "      <th>Mean of the DM-SNR curve</th>\n",
       "      <th>Standard deviation of the DM-SNR curve</th>\n",
       "      <th>Excess kurtosis of the DM-SNR curve</th>\n",
       "      <th>Skewness of the DM-SNR curve</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140.562500</td>\n",
       "      <td>55.683782</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-0.699648</td>\n",
       "      <td>3.199833</td>\n",
       "      <td>19.110426</td>\n",
       "      <td>7.975532</td>\n",
       "      <td>74.242225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102.507812</td>\n",
       "      <td>58.882430</td>\n",
       "      <td>0.465318</td>\n",
       "      <td>-0.515088</td>\n",
       "      <td>1.677258</td>\n",
       "      <td>14.860146</td>\n",
       "      <td>10.576487</td>\n",
       "      <td>127.393580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.015625</td>\n",
       "      <td>39.341649</td>\n",
       "      <td>0.323328</td>\n",
       "      <td>1.051164</td>\n",
       "      <td>3.121237</td>\n",
       "      <td>21.744669</td>\n",
       "      <td>7.735822</td>\n",
       "      <td>63.171909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136.750000</td>\n",
       "      <td>57.178449</td>\n",
       "      <td>-0.068415</td>\n",
       "      <td>-0.636238</td>\n",
       "      <td>3.642977</td>\n",
       "      <td>20.959280</td>\n",
       "      <td>6.896499</td>\n",
       "      <td>53.593661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.726562</td>\n",
       "      <td>40.672225</td>\n",
       "      <td>0.600866</td>\n",
       "      <td>1.123492</td>\n",
       "      <td>1.178930</td>\n",
       "      <td>11.468720</td>\n",
       "      <td>14.269573</td>\n",
       "      <td>252.567306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mean of the integrated profile  \\\n",
       "0                       140.562500   \n",
       "1                       102.507812   \n",
       "2                       103.015625   \n",
       "3                       136.750000   \n",
       "4                        88.726562   \n",
       "\n",
       "    Standard deviation of the integrated profile  \\\n",
       "0                                      55.683782   \n",
       "1                                      58.882430   \n",
       "2                                      39.341649   \n",
       "3                                      57.178449   \n",
       "4                                      40.672225   \n",
       "\n",
       "    Excess kurtosis of the integrated profile  \\\n",
       "0                                   -0.234571   \n",
       "1                                    0.465318   \n",
       "2                                    0.323328   \n",
       "3                                   -0.068415   \n",
       "4                                    0.600866   \n",
       "\n",
       "    Skewness of the integrated profile   Mean of the DM-SNR curve  \\\n",
       "0                            -0.699648                   3.199833   \n",
       "1                            -0.515088                   1.677258   \n",
       "2                             1.051164                   3.121237   \n",
       "3                            -0.636238                   3.642977   \n",
       "4                             1.123492                   1.178930   \n",
       "\n",
       "    Standard deviation of the DM-SNR curve  \\\n",
       "0                                19.110426   \n",
       "1                                14.860146   \n",
       "2                                21.744669   \n",
       "3                                20.959280   \n",
       "4                                11.468720   \n",
       "\n",
       "    Excess kurtosis of the DM-SNR curve   Skewness of the DM-SNR curve  \\\n",
       "0                              7.975532                      74.242225   \n",
       "1                             10.576487                     127.393580   \n",
       "2                              7.735822                      63.171909   \n",
       "3                              6.896499                      53.593661   \n",
       "4                             14.269573                     252.567306   \n",
       "\n",
       "   target_class  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting dataset and cleaning it\n",
    "\n",
    "data = pd.read_csv('pulsar_stars.csv')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming columns\n",
    "data = data.rename(columns={' Mean of the integrated profile':\"mean_profile\",\n",
    "    ' Standard deviation of the integrated profile':\"std_profile\",\n",
    "    ' Excess kurtosis of the integrated profile':\"kurtosis_profile\",\n",
    "    ' Skewness of the integrated profile':\"skewness_profile\", \n",
    "    ' Mean of the DM-SNR curve':\"mean_dmsnr_curve\",\n",
    "    ' Standard deviation of the DM-SNR curve':\"std_dmsnr_curve\",\n",
    "    ' Excess kurtosis of the DM-SNR curve':\"kurtosis_dmsnr_curve\",\n",
    "    ' Skewness of the DM-SNR curve':\"skewness_dmsnr_curve\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1149\n",
      "11379\n"
     ]
    }
   ],
   "source": [
    "# Shuffle data\n",
    "data = data.sample(frac=1)\n",
    "\n",
    "X = data.drop('target_class', axis=1);\n",
    "y = data['target_class'];\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "print(len(y_train[y_train == 1]))\n",
    "print(len(y_train[y_train == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainning SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='linear')  \n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainning Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Logistic Regression Not Workinh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class logistic_regr(object):\n",
    "\n",
    "#     def __init__(self, learning_rate=0.0001, training_iters=100):\n",
    "#         earning_rate = learning_rate # taxa de aprendizado\n",
    "#         self.training_iters = training_iters # iterações de treino\n",
    "        \n",
    "    \n",
    "#     def _logistic(self, X):\n",
    "#         '''Função logística'''\n",
    "#         return  1 / (1 + np.exp(-np.dot(X, self.w_hat)))\n",
    "    \n",
    "    \n",
    "#     def fit(self, X_train, y_train):\n",
    "        \n",
    "#         # formata os dados\n",
    "#         X = X_train.reshape(-1,1) if len(X_train.shape) < 2 else X_train\n",
    "#         X = np.insert(X, 0, 1, 1)\n",
    "               \n",
    "#         # inicia os parâmetros com pequenos valores aleatórios (nosso chute razoável)\n",
    "#         self.w_hat = np.random.normal(0,1, size = X[0].shape)\n",
    "        \n",
    "#         # loop de treinamento\n",
    "#         for _ in range(self.training_iters):\n",
    "            \n",
    "#             gradient = np.zeros(self.w_hat.shape) # inicia o gradiente\n",
    "            \n",
    "#             # atualiza o gradiente com informação de todos os pontos\n",
    "#             for var in range(len(gradient)):\n",
    "#                 gradient[var] += np.dot((self._logistic(X) - y_train), X[:,var])\n",
    "            \n",
    "#             gradient *= self.learning_rate # multiplica o gradiente pela taxa de aprendizado\n",
    "\n",
    "#             # atualiza os parâmetros\n",
    "#             self.w_hat -= gradient\n",
    "            \n",
    "            \n",
    "#     def predict(self, X_test):\n",
    "        \n",
    "#         # formata os dados\n",
    "#         if len(X_test.shape) < 2:\n",
    "#             X = X_test.reshape(-1,1)\n",
    "#         X = np.insert(X, 0, 1, 1)\n",
    "        \n",
    "#         # aplica função logística\n",
    "#         logit = self._logistic(X) \n",
    "        \n",
    "#         # aplica limiar\n",
    "#         return np.greater_equal(logit, 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic = logistic_regr()\n",
    "# logistic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logistic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-dbaf662b7c49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Confusion Matrix:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logistic' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = logistic.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('Accuracy:', accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('Accuracy:', accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('Accuracy:', accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2);\n",
    "dataRed2 = pd.DataFrame(pca.fit_transform(data));\n",
    "dataRed2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRed2['target_class'] = data['target_class'];\n",
    "dataRed2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "positive2 = dataRed2[dataRed2['target_class'] == 1];\n",
    "negative2 = dataRed2[dataRed2['target_class'] == 0];\n",
    "\n",
    "threedee = plt.figure().gca(projection='3d')\n",
    "# threedee.scatter(positive[0], positive[1], positive[2], color='b')\n",
    "# threedee.scatter(negative[0], negative[1], negative[2], color='r')\n",
    "\n",
    "threedee.scatter(positive2[0], positive2[1], color='b')\n",
    "threedee.scatter(negative2[0], negative2[1], color='r')\n",
    "threedee.set_xlabel('0')\n",
    "threedee.set_ylabel('1')\n",
    "threedee.set_zlabel('2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "pca = PCA(n_components=3);\n",
    "dataRed3 = pd.DataFrame(pca.fit_transform(data));\n",
    "dataRed3.head()\n",
    "\n",
    "dataRed3['target_class'] = data['target_class'];\n",
    "\n",
    "positive3 = dataRed3[dataRed3['target_class'] == 1];\n",
    "negative3 = dataRed3[dataRed3['target_class'] == 0];\n",
    "\n",
    "threedee = plt.figure().gca(projection='3d')\n",
    "# threedee.scatter(positive[0], positive[1], positive[2], color='b')\n",
    "# threedee.scatter(negative[0], negative[1], negative[2], color='r')\n",
    "\n",
    "threedee.scatter(positive3[0], positive3[1], positive3[2], color='b')\n",
    "threedee.scatter(negative3[0], negative3[1], negative3[2], color='r')\n",
    "threedee.set_xlabel('0')\n",
    "threedee.set_ylabel('1')\n",
    "threedee.set_zlabel('2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
